services:
  # Ollama - Local LLM inference with GPU support
  ollama:
    image: ollama/ollama:0.5.4
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_NUM_GPU=1
      - OLLAMA_GPU_LAYERS=999
      - OLLAMA_NUM_THREAD=16
      - OLLAMA_MAX_LOADED_MODELS=1          # Single model = more VRAM for context
      - OLLAMA_KEEP_ALIVE=24h
      - OLLAMA_NUM_PARALLEL=8               # Better batching for concurrent requests
      - OLLAMA_FLASH_ATTENTION=1            # Enable flash attention for faster inference
      - OLLAMA_KV_CACHE_TYPE=q8_0           # Quantized KV cache saves ~50% VRAM
    runtime: nvidia
    restart: unless-stopped
    healthcheck:
      test: timeout 10s bash -c ':> /dev/tcp/127.0.0.1/11434' || exit 1
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # Qdrant - Vector database for RAG (optimized configuration)
  qdrant:
    image: qdrant/qdrant:v1.12.4
    container_name: qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_data:/qdrant/storage
    environment:
      # gRPC port for high-performance client connections
      - QDRANT__SERVICE__GRPC_PORT=6334
      # Performance tuning: max concurrent searches
      - QDRANT__SERVICE__MAX_SEARCH_THREADS=4
      # Storage optimization: enable mmap for large collections
      - QDRANT__STORAGE__MMAP_ADVICE=random
      # Enable WAL for durability with good performance
      - QDRANT__STORAGE__WAL__WAL_CAPACITY_MB=64
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
    restart: unless-stopped
    healthcheck:
      test: timeout 10s bash -c ':> /dev/tcp/127.0.0.1/6333' || exit 1
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # Redis - Conversation memory and caching
  redis:
    image: redis:7.4-alpine
    container_name: redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --maxmemory 2gb --maxmemory-policy allkeys-lru --maxclients 1000
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # PostgreSQL - Relational database for metadata and analytics
  postgres:
    image: postgres:16-alpine
    container_name: postgres
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-raguser}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-ragpassword}
      - POSTGRES_DB=${POSTGRES_DB:-ragdb}
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-raguser} -d ${POSTGRES_DB:-ragdb}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # Backend API - FastAPI with RAG pipeline
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    # image: jconover/ai-rag-backend:latest  # Uncomment to use Docker Hub image
    container_name: rag-backend
    ports:
      - "8000:8000"
    volumes:
      - ./data:/data
      - ./scripts:/scripts
    env_file:
      - .env
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 4G
    environment:
      - OLLAMA_HOST=http://ollama:11434
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=${POSTGRES_USER:-raguser}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-ragpassword}
      - POSTGRES_DB=${POSTGRES_DB:-ragdb}
      - PYTHONUNBUFFERED=1
      - LOG_LEVEL=info
      - ENABLE_PROMETHEUS_METRICS=true
    depends_on:
      ollama:
        condition: service_healthy
      qdrant:
        condition: service_healthy
      redis:
        condition: service_healthy
      postgres:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Prometheus - Metrics collection
  prometheus:
    image: prom/prometheus:v2.47.0
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/prometheus/alerts.yml:/etc/prometheus/alerts.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=7d'
      - '--web.enable-lifecycle'
    depends_on:
      - backend
      - alertmanager
    restart: unless-stopped

  # Alertmanager - Alert routing and notifications
  alertmanager:
    image: prom/alertmanager:v0.26.0
    container_name: alertmanager
    ports:
      - "9093:9093"
    volumes:
      - ./monitoring/alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
      - alertmanager_data:/alertmanager
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--web.listen-address=:9093'
      - '--cluster.listen-address='
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:9093/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Grafana - Metrics visualization
  grafana:
    image: grafana/grafana:10.2.0
    container_name: grafana
    ports:
      - "3001:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    depends_on:
      - prometheus
    restart: unless-stopped

  # Frontend - React web UI
  frontend:
    image: jconover/ai-rag-frontend:latest
    container_name: rag-frontend
    ports:
      - "3000:80"
    depends_on:
      - backend
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  ollama_data:
    driver: local
  qdrant_data:
    driver: local
  redis_data:
    driver: local
  postgres_data:
    driver: local
  prometheus_data:
    driver: local
  alertmanager_data:
    driver: local
  grafana_data:
    driver: local

networks:
  default:
    name: rag-network
